{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03000775",
        "outputId": "a3397464-07ed-428d-bb36-f02296f23571"
      },
      "source": [
        "!pip install tenacity"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.12/dist-packages (9.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "790111a0",
        "outputId": "8582f59d-63c7-400b-9cb7-7233f448262b"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from tenacity import retry, stop_after_attempt, wait_fixed, retry_if_exception_type\n",
        "\n",
        "# ==========================================\n",
        "# [필수] Colab 드라이브 마운트 및 설정\n",
        "# ==========================================\n",
        "\n",
        "# 1. Colab 환경 감지 및 드라이브 마운트\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    print(\"[시스템] Colab 환경 감지됨. 드라이브를 마운트합니다...\")\n",
        "\n",
        "    # 이미 마운트 되어있지 않다면 마운트 수행\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "    IS_COLAB = True\n",
        "\n",
        "except ImportError:\n",
        "    IS_COLAB = False\n",
        "    print(\"[시스템] 로컬 환경입니다. (구글 드라이브 파일 스트림 등이 설치되어 있어야 작동함)\")\n",
        "\n",
        "# ==========================================\n",
        "# 사용자 설정 영역 (이 부분을 꼭 확인하세요!)\n",
        "# ==========================================\n",
        "\n",
        "# [중요] 1. 구글 드라이브 웹에서 공유 폴더를 '내 드라이브에 바로가기 추가' 하세요.\n",
        "# [중요] 2. 추가한 바로가기 폴더의 정확한 이름을 아래 변수에 입력하세요.\n",
        "# 예: 내 드라이브에 'LOL_DATA'라는 이름으로 바로가기를 만들었다면 'LOL_DATA' 입력\n",
        "TARGET_SHORTCUT_NAME = 'telemetry'\n",
        "\n",
        "# 경로 설정\n",
        "if IS_COLAB:\n",
        "    # 바로가기를 통해 접근할 원본 데이터 경로 (읽기 전용으로 사용)\n",
        "    # 147GB 데이터를 다운로드하지 않고, 여기서 직접 하나씩 엽니다.\n",
        "    SOURCE_DATA_DIR = f'/content/drive/MyDrive/{TARGET_SHORTCUT_NAME}'\n",
        "\n",
        "    # 결과를 저장할 경로 (내 드라이브)\n",
        "    BASE_RESULT_DIR = '/content/drive/MyDrive/pubg_telemetry_summary'\n",
        "else:\n",
        "    # 로컬 테스트용 경로\n",
        "    SOURCE_DATA_DIR = f'./{TARGET_SHORTCUT_NAME}'\n",
        "    BASE_RESULT_DIR = './extracted_results'\n",
        "\n",
        "# 결과 파일 저장 폴더가 없으면 생성\n",
        "if not os.path.exists(BASE_RESULT_DIR):\n",
        "    os.makedirs(BASE_RESULT_DIR)\n",
        "\n",
        "# [필터 설정]\n",
        "# 특정 이벤트만 뽑고 싶다면 여기에 추가 (예: [\"LogPlayerKill\"])\n",
        "TARGET_EVENTS = [\"LogGameStatePeriodic\",'LogMatchStart','LogParachuteLanding','LogPhaseChange','LogPlayerKillV2',\n",
        "                 'LogPlayerPosition','LogItemPickup', 'LogItemEquip', 'LogItemAttach','LogItemPickupFromCarepackage','LogItemPickupFromLootbox'\n",
        "                 'LogVehicleRide','logvehicleleave','LogMatchEnd']\n",
        "\n",
        "@retry(stop=stop_after_attempt(5), wait=wait_fixed(2), retry=retry_if_exception_type(OSError))\n",
        "def process_json_file(file_path):\n",
        "    \"\"\"\n",
        "    JSON 파일을 열어서 필요한 정보를 추출합니다.\n",
        "    다운로드 없이 드라이브에서 직접 스트리밍으로 읽으므로 용량을 차지하지 않습니다.\n",
        "    또한, LogMatchStart 이벤트에서 맵 이름과 매치 날짜/시간을 추출합니다.\n",
        "    \"\"\"\n",
        "    map_name = None\n",
        "    match_datetime_str = None\n",
        "    team_size_str = 'unknown_team' # 기본값 설정\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        if not isinstance(data, list):\n",
        "            return [], [], map_name, match_datetime_str, team_size_str\n",
        "\n",
        "        # 이벤트 타입 수집 (디버깅용)\n",
        "        unique_event_types = list(set(item.get('_T', 'Unknown') for item in data if isinstance(item, dict)))\n",
        "\n",
        "        # LogMatchStart 이벤트에서 맵 이름, 시간, 팀 크기 추출\n",
        "        for item in data:\n",
        "            if item.get('_T') == 'LogMatchStart':\n",
        "                map_name = item.get('mapName')\n",
        "                _D_raw = item.get('_D')\n",
        "                if _D_raw:\n",
        "                    try:\n",
        "                        # '2024-05-15T12:34:56.789Z' 형식 처리\n",
        "                        dt_obj = datetime.strptime(_D_raw.split('.')[0], '%Y-%m-%dT%H:%M:%S')\n",
        "                        match_datetime_str = dt_obj.strftime('%Y%m%d_%H%M%S')\n",
        "                    except ValueError:\n",
        "                        pass # 날짜 파싱 실패 시 None 유지\n",
        "\n",
        "                team_size = item.get('teamSize')\n",
        "                if team_size == 1:\n",
        "                    team_size_str = 'solo'\n",
        "                elif team_size == 2:\n",
        "                    team_size_str = 'duo'\n",
        "                elif team_size == 4:\n",
        "                    team_size_str = 'squad'\n",
        "                else:\n",
        "                    team_size_str = f'team_{team_size}' if team_size is not None else 'unknown_team'\n",
        "\n",
        "                break # 첫 번째 LogMatchStart만 사용\n",
        "\n",
        "        # 필터링 로직\n",
        "        if TARGET_EVENTS:\n",
        "            filtered_logs = [item for item in data if item.get('_T') in TARGET_EVENTS]\n",
        "        else:\n",
        "            filtered_logs = data\n",
        "\n",
        "        return filtered_logs, unique_event_types, map_name, match_datetime_str, team_size_str\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"[오류] JSON 파싱 불가: {os.path.basename(file_path)}\")\n",
        "        return [], [], map_name, match_datetime_str, team_size_str\n",
        "    except OSError as e:\n",
        "        print(f\"[오류] 파일 읽기 재시도: {os.path.basename(file_path)} - {e}\")\n",
        "        raise # Re-raise to trigger tenacity retry\n",
        "    except Exception as e:\n",
        "        print(f\"[오류] 파일 읽기 실패: {e}\")\n",
        "        return [], [], map_name, match_datetime_str, team_size_str\n",
        "\n",
        "@retry(stop=stop_after_attempt(5), wait=wait_fixed(2), retry=retry_if_exception_type(OSError))\n",
        "def save_match_logs(output_path, logs):\n",
        "    \"\"\"\n",
        "    주어진 로그 리스트를 지정된 경로에 JSONL 형식으로 저장합니다.\n",
        "    OSError 발생 시 재시도합니다.\n",
        "    \"\"\"\n",
        "    with open(output_path, 'w', encoding='utf-8') as output_handle:\n",
        "        for log in logs:\n",
        "            output_handle.write(json.dumps(log, ensure_ascii=False) + '\\n')\n",
        "\n",
        "def main():\n",
        "    print(\"=== 구글 드라이브 대용량 데이터 직접 분석기 ===\")\n",
        "    print(f\"대상 폴더 경로: {SOURCE_DATA_DIR}\")\n",
        "\n",
        "    # 폴더 존재 여부 확인 (바로가기 이름이 틀렸을 경우 대비)\n",
        "    if not os.path.exists(SOURCE_DATA_DIR):\n",
        "        print(f\"\\n[오류] '{SOURCE_DATA_DIR}' 경로를 찾을 수 없습니다.\")\n",
        "        print(\"1. 구글 드라이브에서 공유 폴더를 '내 드라이브에 바로가기 추가' 했는지 확인하세요.\")\n",
        "        print(\"2. 코드 상단의 'TARGET_SHORTCUT_NAME' 변수가 바로가기 이름과 정확히 일치하는지 확인하세요.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n[탐색 시작] 드라이브 내의 JSON 파일을 찾습니다...\")\n",
        "    # recursive=True로 하위 폴더까지 모두 탐색\n",
        "    json_files = glob.glob(os.path.join(SOURCE_DATA_DIR, '**', '*.json'), recursive=True)\n",
        "\n",
        "    if not json_files:\n",
        "        print(f\"폴더 내에 JSON 파일이 없습니다. 경로를 다시 확인해주세요: {SOURCE_DATA_DIR}\")\n",
        "        return\n",
        "\n",
        "    print(f\"총 {len(json_files)}개의 파일을 발견했습니다.\")\n",
        "    print(\"다운로드 없이 직접 분석을 시작합니다. (속도는 인터넷 연결 상태에 따라 다름)\")\n",
        "\n",
        "    # 상태 변수\n",
        "    processed_count = 0\n",
        "    total_logs_saved = 0\n",
        "    first_file_events = None\n",
        "\n",
        "    try:\n",
        "        for file_path in json_files:\n",
        "            # 파일 이름에서 매치 ID 추출 (확장자 제거), 기본값으로 사용\n",
        "            original_match_id = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "            try:\n",
        "                logs, event_types, map_name, match_datetime_str, team_size_str = process_json_file(file_path)\n",
        "            except Exception as e:\n",
        "                print(f\"[치명적 오류] 파일 처리 실패 후 재시도 종료: {os.path.basename(file_path)} - {e}\")\n",
        "                continue # 재시도 실패 시 다음 파일로 건너뛰기\n",
        "\n",
        "            # 매치 ID 생성 (맵 이름과 시간 정보 우선 사용)\n",
        "            parts = []\n",
        "            if match_datetime_str:\n",
        "                parts.append(match_datetime_str)\n",
        "            if team_size_str != 'unknown_team': # 팀 크기가 유효하면 추가\n",
        "                parts.append(team_size_str)\n",
        "            if map_name: # 맵 이름도 유효하면 추가\n",
        "                sanitized_map_name = map_name.replace(' ', '_').replace('/', '_').replace('\\\\', '_')\n",
        "                parts.append(sanitized_map_name)\n",
        "\n",
        "            if parts: # 조합된 정보가 있으면 사용\n",
        "                match_id = '_'.join(parts)\n",
        "            else: # 조합된 정보가 없으면 원본 파일 이름 사용\n",
        "                match_id = original_match_id\n",
        "\n",
        "            # 매치별 결과 파일 경로 생성\n",
        "            match_output_path = os.path.join(BASE_RESULT_DIR, f\"{match_id}.jsonl\")\n",
        "\n",
        "            # 첫 번째 파일 분석 결과 출력 (가이드)\n",
        "            if not first_file_events and event_types:\n",
        "                first_file_events = event_types\n",
        "                print(f\"\\n[정보] 발견된 이벤트 태그 예시:\")\n",
        "                print(f\"{first_file_events[:15]} ... (총 {len(first_file_events)}종)\")\n",
        "                if not TARGET_EVENTS:\n",
        "                    print(\">> 현재 필터 없이 [모든 로그]를 저장 중입니다.\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "            if logs:\n",
        "                try:\n",
        "                    save_match_logs(match_output_path, logs)\n",
        "                    total_logs_saved += len(logs) # 성공적으로 저장된 로그 수 업데이트\n",
        "                except Exception as e:\n",
        "                    print(f\"[치명적 오류] 로그 저장 실패 후 재시도 종료: {os.path.basename(file_path)} -> {os.path.basename(match_output_path)} - {e}\")\n",
        "                    # (선택 사항) 실패한 파일 경로를 기록하여 나중에 재처리할 수 있습니다.\n",
        "                    continue\n",
        "            else:\n",
        "                # 필터링된 로그가 없는 경우 (선택 사항: 경고 메시지 등)\n",
        "                pass\n",
        "\n",
        "            processed_count += 1\n",
        "            if processed_count % 10 == 0:\n",
        "                print(f\"진행률: {processed_count}/{len(json_files)} 파일 완료 | 누적 {total_logs_saved}건 | 현재 파일: {os.path.basename(file_path)}\", end='\\r')\n",
        "\n",
        "    finally:\n",
        "        # 이제 전역 output_handle이 없으므로 닫을 필요 없음\n",
        "        pass\n",
        "\n",
        "    print(f\"\\n\\n[작업 완료] 총 {processed_count}개 파일 처리됨.\")\n",
        "    print(f\"결과는 '{BASE_RESULT_DIR}' 폴더에 개별 매치 파일로 저장되었습니다.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[시스템] Colab 환경 감지됨. 드라이브를 마운트합니다...\n",
            "=== 구글 드라이브 대용량 데이터 직접 분석기 ===\n",
            "대상 폴더 경로: /content/drive/MyDrive/telemetry\n",
            "\n",
            "[탐색 시작] 드라이브 내의 JSON 파일을 찾습니다...\n",
            "총 6757개의 파일을 발견했습니다.\n",
            "다운로드 없이 직접 분석을 시작합니다. (속도는 인터넷 연결 상태에 따라 다름)\n",
            "\n",
            "[정보] 발견된 이벤트 태그 예시:\n",
            "['LogMatchStart', 'LogVehicleRide', 'LogMatchDefinition', 'LogCarePackageSpawn', 'LogMatchEnd', 'LogParachuteLanding', 'LogCarePackageLand', 'LogPlayerDestroyProp', 'LogItemEquip', 'LogItemPickup', 'LogPlayerKillV2', 'LogPhaseChange', 'LogVehicleDestroy', 'LogPlayerLogin', 'LogGameStatePeriodic'] ... (총 45종)\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "[작업 완료] 총 6757개 파일 처리됨.\n",
            "결과는 '/content/drive/MyDrive/pubg_telemetry_summary' 폴더에 개별 매치 파일로 저장되었습니다.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}